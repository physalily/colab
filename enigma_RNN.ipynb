{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enigma_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/physalily/colab/blob/master/enigma_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsKQEbAmKLxW",
        "colab_type": "code",
        "outputId": "2794678d-da02-42e4-bc53-1722fe0773aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_5-w0YEJbaT",
        "colab_type": "code",
        "outputId": "c09de8d2-3e69-48c2-c881-dd57e6ca1e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from keras.layers     import Input, Dense, GRU, LSTM, RepeatVector, Dropout\n",
        "from keras.models   import Model\n",
        "from keras.layers.core import Flatten\n",
        "from keras.callbacks    import LambdaCallback\n",
        "from keras.optimizers  import SGD, RMSprop, Adam\n",
        "from keras.layers.wrappers  import Bidirectional as Bi\n",
        "from keras.layers.wrappers  import TimeDistributed as TD\n",
        "from keras.layers     import merge\n",
        "from keras.utils       import to_categorical\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMsYFxbIRbRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class enigma():\n",
        "    def __init__(self, key1=0, key2=0):\n",
        "        self.rotor1 = rotor(key1, rotorNo=1)\n",
        "        self.rotor2 = rotor(key2, rotorNo=2)\n",
        "        self.key1 = key1\n",
        "        self.key2 = key2\n",
        "        self.reflector = reflector()\n",
        "\n",
        "    def print_rotor(self):\n",
        "        print('rotor_print')\n",
        "        \n",
        "    def encryption(self, char):\n",
        "        x = self.rotor1.current_in(char)\n",
        "        x = self.rotor2.current_in(x)\n",
        "        x = self.reflector.reflect(x)\n",
        "        x = self.rotor2.reverse_in(x)\n",
        "        x = self.rotor1.reverse_in(x)\n",
        "        self.rotor1.indent()\n",
        "        self.rotor2.indent()\n",
        "        return x\n",
        "\n",
        "    def statereset(self):\n",
        "        self.rotor1 = rotor(self.key1, rotorNo=1)\n",
        "        self.rotor2 = rotor(self.key2, rotorNo=2)\n",
        "\n",
        "\n",
        "class reflector():\n",
        "    def __init__(self):\n",
        "        self.reflectorIn  = [chr(ord('a')+i) for i in range(26)]\n",
        "        self.reflectorOut = [chr(ord('a')+i) for i in range(26)]\n",
        "        randlist = [i for i in range(26)]\n",
        "        random.seed(0)\n",
        "        randlist = random.sample(randlist, 26)\n",
        "        for i in range(13):\n",
        "            self.outSwap(randlist[2*i], randlist[2*i+1])\n",
        "            \n",
        "    def reflect(self, char):\n",
        "        return self.reflectorIn[self.reflectorOut.index(char)]\n",
        "\n",
        "    def outSwap(self, indexA, indexB):\n",
        "        tmp = self.reflectorOut[indexA]\n",
        "        self.reflectorOut[indexA] = self.reflectorOut[indexB]\n",
        "        self.reflectorOut[indexB] = tmp\n",
        "\n",
        "class rotor():\n",
        "    def __init__(self, key=0, rotorNo=0):\n",
        "        random.seed(rotorNo)\n",
        "        self.rotorIn  = [chr(ord('a')+i) for i in range(26)]\n",
        "        self.rotorOut = random.sample([chr(ord('a')+i) for i in range(26)], 26)\n",
        "        self.rotorNo = rotorNo\n",
        "        self.state = 1\n",
        "        for i in range(key):\n",
        "            self.indent()\n",
        "    \n",
        "    def current_in(self, char):\n",
        "        return self.rotorOut[self.rotorIn.index(char)]\n",
        "\n",
        "    def reverse_in(self, char):\n",
        "        return self.rotorIn[self.rotorOut.index(char)]\n",
        "\n",
        "    def indent(self):\n",
        "        self.state = self.state+1\n",
        "        if (self.state%(10**(self.rotorNo-1)) == 0):\n",
        "            self.rotorOut = self.rotorOut[1:26]+[self.rotorOut[0]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU2CgVrGLKc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data_raw = ''\n",
        "train_data_raw = ''\n",
        "train_data_cry = ''\n",
        "\n",
        "Alphabet = [chr(ord('a')+i) for i in range(26)]\n",
        "\n",
        "drive_corp_root = '/content/drive/My Drive/bbc/*/*'\n",
        "eni = enigma()\n",
        "for filename in glob.glob(drive_corp_root):\n",
        "  try:\n",
        "    text = open(filename).read()\n",
        "  except Exception as ex:\n",
        "    continue\n",
        "  all_data_buffer = []\n",
        "  raw_data_buffer = []\n",
        "  cry_data_buffer = []\n",
        "\n",
        "  for char in list(text.lower()):\n",
        "    if char in Alphabet:\n",
        "      all_data_buffer.append(char)\n",
        "      raw_data_buffer.append(char)\n",
        "      cry_data_buffer.append(eni.encryption(char))\n",
        "    else:\n",
        "      all_data_buffer.append(char)\n",
        "\n",
        "  all_data_raw += ''.join(all_data_buffer)\n",
        "  train_data_raw += ''.join(raw_data_buffer)\n",
        "  train_data_cry += ''.join(cry_data_buffer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4TLC4iyOkJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_raw = np.array([(ord(i)-ord('a')) for i in train_data_raw])\n",
        "train_data_cry = np.array([(ord(i)-ord('a')) for i in train_data_cry])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhcUUGNoA3mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_raw = to_categorical(train_data_raw[:3700000])\n",
        "one_hot_cry = to_categorical(train_data_cry[:3700000])\n",
        "one_hot_raw = one_hot_raw.reshape([-1, 100, 26])\n",
        "one_hot_cry = one_hot_cry.reshape([-1, 100, 26])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiW4tmG4PEKh",
        "colab_type": "code",
        "outputId": "0e4b8020-b27a-42ab-e51a-3b53260c899c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "timesteps = 100\n",
        "\n",
        "inputs  = Input(shape=(timesteps, 26))\n",
        "x         = Bi(GRU(512, dropout=0.10, recurrent_dropout=0.25, return_sequences=True))(inputs)\n",
        "x         = TD(Dense(3000, activation='relu'))(x)\n",
        "x         = Dropout(0.2)(x)\n",
        "x         = TD(Dense(3000, activation='relu'))(x)\n",
        "x         = Dropout(0.2)(x)\n",
        "x         = TD(Dense(26, activation='softmax'))(x)\n",
        "\n",
        "decript = Model(inputs, x)\n",
        "decript.compile(optimizer=Adam(), loss='categorical_crossentropy')\n",
        "decript.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 100, 26)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 100, 1024)         1655808   \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 100, 3000)         3075000   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100, 3000)         0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 100, 3000)         9003000   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100, 3000)         0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 100, 26)           78026     \n",
            "=================================================================\n",
            "Total params: 13,811,834\n",
            "Trainable params: 13,811,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAGKSRzGRTgP",
        "colab_type": "code",
        "outputId": "84566482-3d30-4868-e3ca-2d9e9653c25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "decript.fit(x=one_hot_cry, y=one_hot_raw,\n",
        "            batch_size=300,\n",
        "            epochs=35,\n",
        "            validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33300 samples, validate on 3700 samples\n",
            "Epoch 1/35\n",
            "33300/33300 [==============================] - 132s 4ms/step - loss: 2.7147 - val_loss: 2.6049\n",
            "Epoch 2/35\n",
            "33300/33300 [==============================] - 132s 4ms/step - loss: 2.5804 - val_loss: 2.4622\n",
            "Epoch 3/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 2.4752 - val_loss: 2.3565\n",
            "Epoch 4/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 2.2108 - val_loss: 1.6193\n",
            "Epoch 5/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 1.5072 - val_loss: 0.5661\n",
            "Epoch 6/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.8085 - val_loss: 0.1223\n",
            "Epoch 7/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.4075 - val_loss: 0.0341\n",
            "Epoch 8/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.2270 - val_loss: 0.0146\n",
            "Epoch 9/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.3309 - val_loss: 0.1827\n",
            "Epoch 10/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.2721 - val_loss: 0.0089\n",
            "Epoch 11/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.1444 - val_loss: 0.0054\n",
            "Epoch 12/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.0966 - val_loss: 0.0027\n",
            "Epoch 13/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.0805 - val_loss: 0.0020\n",
            "Epoch 14/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0800 - val_loss: 0.0047\n",
            "Epoch 15/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0895 - val_loss: 0.0017\n",
            "Epoch 16/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0630 - val_loss: 0.0013\n",
            "Epoch 17/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0582 - val_loss: 0.0014\n",
            "Epoch 18/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0530 - val_loss: 0.0010\n",
            "Epoch 19/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0523 - val_loss: 2.4920e-04\n",
            "Epoch 20/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.0505 - val_loss: 5.1223e-04\n",
            "Epoch 21/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0477 - val_loss: 0.0011\n",
            "Epoch 22/35\n",
            "33300/33300 [==============================] - 132s 4ms/step - loss: 0.0510 - val_loss: 7.8221e-04\n",
            "Epoch 23/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0473 - val_loss: 1.3830e-04\n",
            "Epoch 24/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0445 - val_loss: 1.2659e-04\n",
            "Epoch 25/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0410 - val_loss: 2.7899e-04\n",
            "Epoch 26/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0413 - val_loss: 1.2886e-04\n",
            "Epoch 27/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.0394 - val_loss: 1.8332e-04\n",
            "Epoch 28/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0400 - val_loss: 5.8400e-05\n",
            "Epoch 29/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0370 - val_loss: 2.8862e-05\n",
            "Epoch 30/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0358 - val_loss: 2.6886e-05\n",
            "Epoch 31/35\n",
            "33300/33300 [==============================] - 131s 4ms/step - loss: 0.0346 - val_loss: 7.7873e-05\n",
            "Epoch 32/35\n",
            "33300/33300 [==============================] - 129s 4ms/step - loss: 0.0351 - val_loss: 3.9410e-05\n",
            "Epoch 33/35\n",
            "33300/33300 [==============================] - 129s 4ms/step - loss: 0.0347 - val_loss: 5.2297e-05\n",
            "Epoch 34/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.0324 - val_loss: 1.2227e-04\n",
            "Epoch 35/35\n",
            "33300/33300 [==============================] - 130s 4ms/step - loss: 0.0322 - val_loss: 4.7228e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f28de72e4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esGxbjG9qhsZ",
        "colab_type": "code",
        "outputId": "a123799f-8954-4d46-86fd-b15c2ee40b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "testA = [chr(ord('r')) for i in range(100)]\n",
        "testA = ['h','e','l','l','o','w','o','r','l','d','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o','h','e','l','l','o']\n",
        "testEnigmaA = enigma()\n",
        "print(len(testA))\n",
        "testAcrypt = [testEnigmaA.encryption(test) for test in testA]\n",
        "testEnigmaA.statereset()\n",
        "testADecry = [testEnigmaA.encryption(test) for test in testA]\n",
        "testpre = np.array([(ord(i)-ord('a')) for i in testAcrypt])\n",
        "testpre = to_categorical(testpre)\n",
        "testpre = testpre.reshape((1, 100, 26))\n",
        "test = decript.predict(testpre)\n",
        "test = np.argmax(test, axis=2)\n",
        "print(test.shape)\n",
        "test = test.reshape(100,)\n",
        "test = [chr(ord('a')+i) for i in test]\n",
        "test[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "(1, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeKJ-pD3tZSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decript.save('/content/drive/My Drive/tf_model/enigma_rnn3')\n",
        "decript.save_weights('/content/drive/My Drive/tf_model/enigma_rnn3_w.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZmcbAu1kSU2",
        "colab_type": "code",
        "outputId": "978884fb-9673-4187-9117-652efb4298f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[x for x in 'hell world' if x.strip()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h', 'e', 'l', 'l', 'w', 'o', 'r', 'l', 'd']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}